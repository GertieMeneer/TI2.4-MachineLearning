{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a78768-c550-45ea-b981-fb204f46dcd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the working of the Jupyter notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41863b9f-a54c-4ffe-ae9c-5b05e5479c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Hello world!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7dbb41-db0a-49c9-a843-849afb2d0736",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opdracht 4.1: ZTDL 1 - First Deep Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ff2a79-fea7-4396-8d29-a7f06f76c9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a67dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hier worden de nodige bibliotheken geïmporteerd: NumPy voor numerieke berekeningen, \n",
    "# %matplotlib inline om ervoor te zorgen dat de grafieken binnen de notebook worden weergegeven, \n",
    "# en Matplotlib voor het maken van de grafieken."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb8e3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_circles\n",
    "\n",
    "X, y = make_circles(n_samples=1000,\n",
    "                    noise=0.1,\n",
    "                    factor=0.2,\n",
    "                    random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6146f381",
   "metadata": {},
   "outputs": [],
   "source": [
    "# De make_circles functie van Scikit-learn wordt gebruikt om een dataset te maken met cirkelvormige clusters. \n",
    "# De n_samples parameter bepaalt het aantal punten in de dataset, noise voegt ruis toe aan de gegevens \n",
    "# en factor bepaalt de afstand tussen de twee cirkels. random_state zorgt ervoor dat de gegenereerde gegevens herhaalbaar zijn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6db268",
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d93c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dit geeft de gegevens X weer, die de coördinaten van de punten zijn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bbda058",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f90001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dit toont de vorm van de gegevens X, wat het aantal rijen en kolommen van de dataset weergeeft."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81e019f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 5))\n",
    "plt.plot(X[y==0, 0], X[y==0, 1], 'ob', alpha=0.5)\n",
    "plt.plot(X[y==1, 0], X[y==1, 1], 'xr', alpha=0.5)\n",
    "plt.xlim(-1.5, 1.5)\n",
    "plt.ylim(-1.5, 1.5)\n",
    "plt.legend(['0', '1'])\n",
    "plt.title(\"Blue circles and Red crosses\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366b2c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hier worden de punten gevisualiseerd met Matplotlib. \n",
    "# De punten worden geplot als blauwe cirkels ('ob') en rode kruizen ('xr'). \n",
    "# De alpha parameter bepaalt de transparantie van de punten. \n",
    "# Vervolgens worden de grenzen van de plot ingesteld en een legende en titel toegevoegd."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921f956e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(4, input_shape=(2,), activation='tanh'))\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(SGD(learning_rate=0.5), 'binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X, y, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8d5cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nu begint het gedeelte dat een neuraal netwerk maakt en traint. \n",
    "# Eerst wordt een sequentiële model gedefinieerd. \n",
    "# Vervolgens worden de lagen van het model toegevoegd: \n",
    "# een invoerlaag met 2 neuronen (input_shape=(2,)), een verborgen laag met 4 neuronen en tanh activatiefunctie, \n",
    "# en een uitvoerlaag met 1 neuron en sigmoid activatiefunctie. \n",
    "# Het model wordt gecompileerd met Stochastic Gradient Descent (SGD) als optimizer en binair kruis-entropieverliesfunctie. \n",
    "# Het model wordt getraind op de gegevens X en y gedurende 20 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "923f39d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "hticks = np.linspace(-1.5, 1.5, 101)\n",
    "vticks = np.linspace(-1.5, 1.5, 101)\n",
    "aa, bb = np.meshgrid(hticks, vticks)\n",
    "ab = np.c_[aa.ravel(), bb.ravel()]\n",
    "c = model.predict(ab)\n",
    "cc = c.reshape(aa.shape)\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.contourf(aa, bb, cc, cmap='bwr', alpha=0.2)\n",
    "plt.plot(X[y==0, 0], X[y==0, 1], 'ob', alpha=0.5)\n",
    "plt.plot(X[y==1, 0], X[y==1, 1], 'xr', alpha=0.5)\n",
    "plt.xlim(-1.5, 1.5)\n",
    "plt.ylim(-1.5, 1.5)\n",
    "plt.legend(['0', '1'])\n",
    "plt.title(\"Blue circles and Red crosses\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4bbff6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dit deel visualiseert de beslissingsgrens van het getrainde model. \n",
    "# Eerst worden roosterpunten gemaakt om te voorspellen met het model. \n",
    "# Vervolgens worden voorspellingen gedaan op deze roosterpunten en gevisualiseerd met een contourplot. \n",
    "# Daarna worden de originele punten geplot, net als eerder, maar nu bovenop de contourplot. \n",
    "# De legende en titel worden toegevoegd voor de plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47cae02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opdracht 4.2: ZTDL 2 - Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "317c2238",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEF'S DEEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7551af30",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('Datasets/ifood_df.csv')\n",
    "\n",
    "df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c894b865",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b6ee2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2e9c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.query(\"Kidhome > 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7036e302",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values('Kidhome', ascending = False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3191749b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Income'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6765ea6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.groupby(['Kidhome', 'Teenhome'])['Income'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a8017c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Income'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9315a136",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Income'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29862404",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Income'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ebfaaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Income'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e373754",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Kidhome'] == 1\n",
    "kidhome = df.corr()['Income'].sort_values()\n",
    "kidhome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "026899ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['Income']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bbdd2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['Income']].plot(style='.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6947a8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot(style='.', x='Age', y='Income')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4477e8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['Kidhome']].plot(kind='hist',\n",
    "        bins=50,\n",
    "        title='Histogram',\n",
    "        alpha=0.6);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46c511f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['Income']].plot(kind='kde');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2416570c",
   "metadata": {},
   "outputs": [],
   "source": [
    "incomeMeasurement = df['Income'] > 40000\n",
    "piecounts = incomeMeasurement.value_counts()\n",
    "piecounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0ec295",
   "metadata": {},
   "outputs": [],
   "source": [
    "piecounts.plot(kind='pie',\n",
    "               figsize=(5, 5),\n",
    "               explode=[0, 0.15],\n",
    "               labels=['<= 40000', '> 40000'],\n",
    "               autopct='%1.2f%%',\n",
    "               shadow=True,\n",
    "               startangle=90,\n",
    "               fontsize=16);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86d7740",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GERT-JAN'S DEEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14be0bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('Datasets/vehicle_population_statistics.csv')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a800cddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb27948",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233b330d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.query(\"Cars > 100000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4280ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values('Cars', ascending = True).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01194ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Cars'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6623c6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.groupby(['Kidhome', 'Teenhome'])['Income'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26a6f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Cars'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e46607a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Cars'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa434474",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Cars'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b007ce89",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Cars'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1fbd147",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Kidhome'] == 1\n",
    "kidhome = df.corr()['Income'].sort_values()\n",
    "kidhome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b68efe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['Income']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8826fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['Income']].plot(style='.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f495aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot(style='.', x='Age', y='Income')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35664048",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['Kidhome']].plot(kind='hist',\n",
    "        bins=50,\n",
    "        title='Histogram',\n",
    "        alpha=0.6);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1055bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['Income']].plot(kind='kde');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eda40fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "incomeMeasurement = df['Income'] > 40000\n",
    "piecounts = incomeMeasurement.value_counts()\n",
    "piecounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1965e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "piecounts.plot(kind='pie',\n",
    "               figsize=(5, 5),\n",
    "               explode=[0, 0.15],\n",
    "               labels=['<= 40000', '> 40000'],\n",
    "               autopct='%1.2f%%',\n",
    "               shadow=True,\n",
    "               startangle=90,\n",
    "               fontsize=16);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08424a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opdracht 4.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38992655",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Datasets/car_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d94d381",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam, SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ce1935",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('Datasets/car_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98fb42f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x = data['Kms_Driven'].values\n",
    "y = data['Selling_Price'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0c0075",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7ff297",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(1, input_shape=(1,)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8b1e7f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82bc3bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(Adam(learning_rate=0.8), 'mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26351f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x, y, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6dd6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9042b5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.plot(kind='scatter', x='Kms_Driven', y='Selling_Price')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb04d71",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(df['Kms_Driven'], y_pred, color='red')\n",
    "plt.title(\"Prediction\")\n",
    "plt.xlabel('Kilometers Driven')\n",
    "plt.ylabel('Predicted Values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362fda39",
   "metadata": {},
   "outputs": [],
   "source": [
    "W, B = model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23770b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d282c028",
   "metadata": {},
   "outputs": [],
   "source": [
    "B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d845db48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa360f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opdracht 5.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3de703b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957dcf22",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Image(filename = \"Sketch Neural Network.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597fc994",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Een shallow model is een model met maar 1 laag. En dat kan alleen lineaire beslissingsgrenzen leren.\n",
    "# Als de dataset dus niet-liniair is zal het model niet goed werken.\n",
    "# Ook is het shallow model te simpel om ingewikkeldere patronen in data te herkennen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6912e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c539f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opdracht 5.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cacf5da7",
   "metadata": {},
   "source": [
    "## Multiclass classification\n",
    "\n",
    "### The Iris dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa717ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "df = pd.read_csv('Datasets/vehicle_population_statistics.csv')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af16437",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('Datasets/iris.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5124a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.pairplot(df, hue=\"species\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344f98a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc17d0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('species', axis=1)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde39728",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_names = df['species'].unique()\n",
    "target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad65d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_dict = {n:i for i, n in enumerate(target_names)}\n",
    "target_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47576e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "y= df['species'].map(target_dict)\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d148b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58a311e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_cat = to_categorical(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4576275",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_cat[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef733d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X.values, y_cat,\n",
    "                                                    test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec700a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(3, input_shape=(4,), activation='softmax'))\n",
    "model.compile(Adam(learning_rate=0.1),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28fd7ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train, epochs=20, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca94c21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3428a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97288066",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_class = np.argmax(y_test, axis=1)\n",
    "y_pred_class = np.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0251d5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a53b50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test_class, y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62dbe26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test_class, y_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bfaea90",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Image(filename = \"Opdr 5.3 Sketch.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542cf2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dit model heeft 1 hidden layer en een output layer.\n",
    "# Er wordt hierbij softmax gebruikt omdat het de output van het netwerk omzet in waarschijnlijkheden over meerdere klassen.\n",
    "# Dit is handig voor de iris dataset, waarbij elke sample tot 1 van de 3 klassen behoort. Hierdoor kan het model effectief getraind worden.\n",
    "# Hieronder zijn de resultaten te zien op basis van verschillende leersnelheden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0b0c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename = \"Opdr 5.3 Results.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90acbd63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hier zien we dat een snelle leersnelheid een negatief resultaat heeft op het model waardoor de accuracy flink naar beneden gaat.\n",
    "# Er lijkt geen sprake te zijn van overfitting. De nauwkeurigheid op de testdata is consistent met de nauwkeurigheid op de trainingsdata.\n",
    "# Presicion: hoevel van de voorpselde positieve resultaten daadwerkelijk positief zijn.\n",
    "# Recall: hoeveel van de werkelijk positieve getallen juist zijn geidentificeerd door het model.\n",
    "# F1-sscore: 2x (gemiddelde van precision en recall)\n",
    "# Het classificatiemodel is betrouwbaarder bij een leersnelheid van 0.1 dan bij een leersnelheid van 0.0001 voor de Iris dataset.\n",
    "# In de confusion matrix worden 4 verschillende uitkomsten weergegeven: TP, FP, TN, FN. Hieruit kan je zien hoe goed het model presteert in het classificeren an de verschillende klassen.\n",
    "# In een confusion matrix kan je fouten identificeren, je kan de prestatie per klasse zien, de nauwkeurigheid en betrouwbaarheid en de optimalisatie en verbetering van het model zien. Het is dus belangrijke informatie over het model om te kunnen zien hoe goed het model daadwerkelijk is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51fbc150",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360df872-301f-4409-adb6-4b173f06df7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opdracht 5.2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ffbde22-c46b-4bab-ad60-2452dd86cfa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(filename = \"Sketch Neural Network 2.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6bafd1c-f551-4e6d-88d5-6c7441a74fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dit model heeft 3 lagen 2 hidden layers en 1 output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360622ed-e61e-4992-94ab-7908f2ea1420",
   "metadata": {},
   "outputs": [],
   "source": [
    "# De gebruikte Optimizer is Adam. \n",
    "# Een optimizer is een algoritme dat de gewichten van het neurale netwerk aanpast om de verliesfunctie te minimaliseren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b582e3ab-09ef-4c32-bc9f-76911843b707",
   "metadata": {},
   "outputs": [],
   "source": [
    "# De accuracy score van de train set is 0.999 en de accuracy score van de test set is 1.000 \n",
    "# Dit betekent dat het model tijdens de train set goed kan classificeren en tijdens de test set kan het model ook goed\n",
    "# classificeren met nieuwe data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56172431",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Het verschil tussen in accuracy tussen de trainingset en de testset is klein. Ook zijn beide scores hoog.\n",
    "# Dit betekent dat er waarschijnlijk geen sprake is van overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325a8f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opdracht 5.4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59aea7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'Datasets/mushroom_cleaned.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a7fcb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Separate features and target variable\n",
    "X = data.drop('class', axis=1)\n",
    "y = data['class']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf486aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Build the neural network\n",
    "model = Sequential()\n",
    "model.add(Dense(16, input_shape=(X_train.shape[1],), activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(Adam(learning_rate=0.01), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=10, validation_split=0.1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2cec14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "results = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Loss: {results[0]}\")\n",
    "print(f\"Test Accuracy: {results[1]}\")\n",
    "\n",
    "# Predictions and confusion matrix\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "y_test_pred = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
    "\n",
    "print(classification_report(y_test, y_test_pred))\n",
    "print(confusion_matrix(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810a159b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f914b29",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_img' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_24584\\450993305.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;31m# Load images and preprocess them\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[0mimage_width\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage_height\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m224\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m224\u001b[0m  \u001b[1;31m# Define your desired image size\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m \u001b[0mimages\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mload_and_preprocess_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_filename\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mimage_filename\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'images'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;31m# Step 3: Convert labels to numerical format\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_24584\\450993305.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;31m# Load images and preprocess them\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[0mimage_width\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage_height\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m224\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m224\u001b[0m  \u001b[1;31m# Define your desired image size\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m \u001b[0mimages\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mload_and_preprocess_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_filename\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mimage_filename\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'images'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;31m# Step 3: Convert labels to numerical format\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_24584\\450993305.py\u001b[0m in \u001b[0;36mload_and_preprocess_image\u001b[1;34m(image_filename)\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[0mimage_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mf\"Datasets/license_plate/{image_filename}\"\u001b[0m  \u001b[1;31m# Update with the path to your image directory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[1;31m# Load image\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m     \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_img\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_width\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage_height\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m     \u001b[1;31m# Convert image to array\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[0mimg_array\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimg_to_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'load_img' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import pandas as pd  # Importeer pandas\n",
    "\n",
    "\n",
    "# Step 1: Read the CSV file\n",
    "csv_file = \"Datasets/license_plate/lpr.csv\"\n",
    "data = pd.read_csv(csv_file)\n",
    "\n",
    "# Select only 100 images\n",
    "data = data.sample(n=10000, random_state=42)\n",
    "\n",
    "# Step 2: Load and preprocess images\n",
    "def load_and_preprocess_image(image_filename):\n",
    "    image_path = f\"Datasets/license_plate/{image_filename}\"  # Update with the path to your image directory\n",
    "    # Load image\n",
    "    img = load_img(image_path, target_size=(image_width, image_height))\n",
    "    # Convert image to array\n",
    "    img_array = img_to_array(img)\n",
    "    # Preprocess image (e.g., normalize pixel values)\n",
    "    # (You can add more preprocessing steps here if needed)\n",
    "    img_array /= 255.0  \n",
    "    return img_array\n",
    "\n",
    "# Load images and preprocess them\n",
    "image_width, image_height = 224, 224  # Define your desired image size\n",
    "images = [load_and_preprocess_image(image_filename) for image_filename in data['images']]\n",
    "\n",
    "# Step 3: Convert labels to numerical format\n",
    "label_encoder = LabelEncoder()\n",
    "encoded_labels = label_encoder.fit_transform(data['labels'])\n",
    "num_classes = len(label_encoder.classes_)\n",
    "\n",
    "# Convert numerical labels to one-hot encoded format\n",
    "one_hot_labels = to_categorical(encoded_labels, num_classes=num_classes)\n",
    "\n",
    "# Step 4: Split the dataset into training and validation sets\n",
    "train_images, val_images, train_labels, val_labels = train_test_split(images, one_hot_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 5: Define the CNN model architecture\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(image_width, image_height, 3)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))  # Use softmax activation for multi-class classification\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Print model summary\n",
    "print(model.summary())\n",
    "\n",
    "# Step 6: Train the model\n",
    "epochs = 25\n",
    "batch_size = 32\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='accuracy', min_delta=0, patience=5, verbose=1, mode='max', baseline=0.85, restore_best_weights=True)\n",
    "print(\"Training started...\")\n",
    "history = model.fit(np.array(train_images), train_labels, epochs=epochs, batch_size=batch_size, validation_data=(np.array(val_images), val_labels), callbacks=[early_stopping])\n",
    "\n",
    "# Print training history\n",
    "print(\"Training completed.\")\n",
    "print(\"Training history:\")\n",
    "print(history.history)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ec8939a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained model saved as 'trained_license_plate_model.h5'.\n"
     ]
    }
   ],
   "source": [
    "# Step 7: Save the trained model\n",
    "model.save(\"trained_license_plate_model.h5\")\n",
    "print(\"Trained model saved as 'trained_license_plate_model.h5'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "116b191e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted license plate: 6561HM\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load the trained model\n",
    "model = load_model(\"trained_license_plate_model.h5\")  # Update with the path to your trained model file\n",
    "\n",
    "# Load and preprocess the new image\n",
    "new_image_path = \"russian_license_plate.jpg\"  # Update with the path to your new image\n",
    "new_image = load_and_preprocess_image(new_image_path)\n",
    "\n",
    "# Make predictions on the new image\n",
    "predictions = model.predict(np.expand_dims(new_image, axis=0))\n",
    "\n",
    "# Decode predictions\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "predicted_labels = label_encoder.inverse_transform(predicted_classes)\n",
    "\n",
    "# Output the predicted labels\n",
    "print(\"Predicted license plate:\", ''.join(predicted_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8bafc96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999aeae5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
